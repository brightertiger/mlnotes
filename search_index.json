[["index.html", "Notes on ML 1 About", " Notes on ML brightertiger 2022-03-20 1 About Hi I am brightertiger! I am a data scientist looking to expand my knowledge about ML. This is a collection of notes on machine learning concepts based mostly on Statquest along with a few other resources. "],["decision-trees-random-forests.html", "2 Decision Trees &amp; Random Forests", " 2 Decision Trees &amp; Random Forests 2.0.1 Decision Trees Recursively split the input / feature space using stubs i.e. decision rules Splits are parallel to the axis Mathematical Represenation \\(R_j = \\{ x : d_1 &lt;= t_1, d_2 &gt;= t_2 ... \\}\\) \\(\\hat Y_i = \\sum_j w_j I\\{x_i \\in R_j\\}\\) \\(w_j = \\frac{\\sum_i y_i I \\{x_i \\in R_j\\}}{\\sum_i I \\{x_i \\in R_j\\}}\\) Types of Decision Trees Binary Splits Classification and Regression Trees (CART) C4.5 Multiple Splits: CHAID (Chi-Square Automatic Interaction Detection) ID3 2.0.2 Splitting Split Criteria for Classification Trees The nodes are split to decrease inpurity in classification Gini Criterion \\(1 - \\sum_C p_{i}^2\\) Probability that observation belongs to class i: \\(p_i\\) Misclassification: For a given class (say i): \\(p_i \\times p_{k \\ne i} = p_i \\times (1 - p_i)\\) Across all classes: \\(\\sum_C p_i \\times (1 - p_i)\\) \\(\\sum_C p_i - \\sum_c p_{i}^2\\) \\(1 - \\sum_c p_{i}^2\\) Ranges from (0, 0.5) Entropy Criterion Measure of uncertainly of a random variable Given an event E p(E) = 1 \\(\\implies\\) No Surprise p(E) = 0 \\(\\implies\\) Huge Surprise Informaion Content: \\(I(E) = \\log(1 / p(E))\\) Entropy is the expectation of this information content \\(H(E) = - \\sum p(E) \\log(p(E))\\) Maximum when all outcomes have same probability of occurance Ranges from (0, 1) Split Criteria for Regression Trees Sum-Squared Error \\(\\sum_i (Y_i - \\bar Y)^2\\) Finding the Split For any candidate value: Calculate the weighted average reduction in impurity / error Weights being the number of observations flowing in the child nodes Starting Gini \\(\\text{Gini}_{\\text{Root}}\\) \\(N_{\\text{Root}}\\) After Split Child Nodes \\(\\text{Gini}_{\\text{Left}}, N_{\\text{Left}}\\) \\(\\text{Gini}_{\\text{Right}}, N_{\\text{Right}}\\) Updated Gini \\(\\frac{N_{\\text{Left}}}{N_{\\text{Root}}} \\times \\text{Gini}_{\\text{Left}} + \\frac{N_{\\text{Right}}}{N_{\\text{Root}}} \\times \\text{Gini}_{\\text{Right}}\\) Find the split, the results in minimum updated Gini Updated Gini &lt;= Starting Gini Greedy algorithms to find the best splits 2.0.3 Bias-Variance Trade-off Bias Measures ability of an ML algorithm to model true relationship between features and target Simplifying assumptions made by the model to learn the relationship Example: Linear vs Parabolic relationship Low Bias: Less restrictive assupmtions High Bias: More restrictive assumptions Variance The difference in model performance across different datasets drawn from the same distribution Low Variance: Small changes to model perforamance with changes in datasets High Variance: Large changes to model perforamance with changes in datasets Irreducible Error Bayes error Cannot be reduced irrespective of the model form Best model minimizes: \\(\\text{MSE} = \\text{bias}^2 + \\text{variance}\\) Decision trees have low bias and high variance Decision trees are prone to overfitting Noisy Samples Small data samples in nodes down the tree Tree Pruning solves for overfitting Adding a cost term to objetive which captures tree complexity \\(\\text{Tree Score} = SSR + \\alpha T\\) As the tree grows in size, the reduction in SSR has to more than offset the complexity cost 2.0.4 Nature of Decision Trees Decision Trees can model non-linear relationships (complex deicison boundaries) Spline regressions cannot achieve the same results Spline adds indicator variables to capture interactions and create kinks But the decision boundary has to be continuous The same restriction doesn’t apply to decision trees Decision Trees don’t require feature sscaling Decision Trees are less sensitive to outliers Outliers are of various kinds: Outliers: Points with extreme values Input Features Doesn’t impact Decision Trees Split finding will ignore the extreme values Output / Target Influential / High-Leverage Points: Undue influence on model Decision Trees cannot extrapolate well to ranges outside the training data Decision trees cannot capture linear time series based trends / seasonality 2.0.5 Bagging Bootstrap Agrregation Sampling with repetition Given Dataset of Size N Draw N samples with replacement Probability that a point (say i) never gets selected \\((1 - \\frac{1}{N})^N \\approx \\frac{1}{e}\\) Probability that a point (say i) gets selected atleast once \\(1 - \\frac{1}{e} \\approx 63\\%\\) 2.0.6 Random Forest Use bootstrap aggregation (bagging) to create multiple datasets “Random” subspace of dataset Use subset of variables for split at each node sqrt for classification m//3 for regression Comparison to single decision tree Bias remains the same Variance decreases Randomness in data and slpits reduces the correlation in prediction across trees Let \\(\\hat y_i\\) be the prediction from ith tree in the forest Let \\(\\sigma^2\\) be the variance of \\(\\hat y_i\\) Let \\(\\rho\\) be the correlation between two trees in the forest \\(V(\\sum_i \\hat y_i) = \\sum V(\\hat y_i) + 2 \\sum\\sum COV(\\hat y_i, \\hat y_j)\\) \\(V(\\sum_i \\hat y_i) = n \\sigma^2 + n(n-1) \\rho \\sigma^2\\) \\(V( \\frac{1}{n} \\sum_i \\hat y_i) = \\rho \\sigma^2 + \\frac{1-\\rho}{n} \\sigma^2\\) Variance goes down as more trees are added, but bias stays put Output Combination Majority Voting for Classification Averaging for Regression Out-of-bag (OOB) Error Use the non-selected rows in bagging to estimate model performance Comparable to cross-validaiton results Proximity Matrix Use OOB observations Count the number of times each pair goes to the same terminal node Identifies observations that are close/similar to each other 2.0.7 ExtraTrees Extremely Randomized Trees Bagging: ExtraTrees: No Extremely Randomized Trees: Yes Mutiple trees are built using: Random variable subset for splitting Random threshold subsets for a variable for splitting 2.0.8 Variable Importance Split-based importance If variable j is used for split Calculate the improvement in Gini at the split Sum this improvement across all trees and splits wherever jth variable is used Alternate is to calculate the number of times variable is used for splitting Biased in favour of continuous variables which can be split multiple times Permutation-based importance / Boruta Use OOB samples to calculate variable importance Take bth tree: Pass the OOB samples and calculate accuracy Permuate jth variable and calculate the decrease in accuracy Average this decrease in accuracy across all trees to calculate variable importance for j Effect is simialr to setting the coefficient to 0 in regression Takes into account if good surrogates are present in the dataset Partial Dependence Plots Marginal effect of of a feature on target Understand the relationship between feature and target Assumes features are not correlated \\(\\hat f(x_s) =\\frac{1}{C} \\sum f(x_s,x_i)\\) Average predictions over all other variables Can be used to identify important interactions Friedman’s H Statistic If features don’t interact Joint PDP can be decomposed into marginals Shapely Values Model agnositc feature importance LIME "],["boosting.html", "3 Boosting", " 3 Boosting 3.0.1 Overview Combine multiple rules of thumb to make an accurate and informed decision Bagging: Models are buit in parallel on different data subsets Boosting: Models are built in sequence with modified different samples weights \\(F(x_i) = \\sum_m \\alpha_m f_m(x_i)\\) \\(f_m\\) and \\(\\alpha_m\\) are fit jointly PAC Learning Framework Probably Approximately Correct Is the problem learnable? Model has error \\(&lt; \\epsilon\\) with probability \\(&gt; (1 -\\delta)\\) An algorithm that satisfies the PAC thresholds is a strong learner Strong learners are complex models with many parameters and require a lot of training data Weak learners are algorithms that perform slightly better than random guessing Schapire: Strength of Weak Learnability If a problem can be solved by strong learner, it can be solved by a collection of weak learners. Hypothesis boosting mechanism Construct three hypotheses, trained on different data subsets H1: Complete Data H2: Balanced Sampling of correct and incorrect predictions from H1 H3: Disagreements between H1 and H2 predictions Scoring: Majority Voting of H1, H2 and H3 Improved performance but cannot be scaled easily Adaboost - Adaptive Boosting Additive Model Contruct many hypothesis (more than three) The importance/weight of each new hypotheses added “adapts” or changes \\(\\alpha_m = \\frac{1}{2}\\log\\lbrack \\frac{1-\\epsilon_m}{\\epsilon_m} \\rbrack\\) \\(\\epsilon_m\\) si the weighted classification error Every sample has a weight associated while constructing a weak hypothesis Exponential Weighting scheme Correctly Classifier: \\(w_i = w_i \\times \\exp^{\\alpha}\\) Incorrectly Classifier: \\(w_i = w_i \\times \\exp^{-\\alpha}\\) Underfitting: Not enough hypothesis added to ensemble Overfitting: Not using weak learners as hypothesis Gradient Boosting Uses gradients of the loss function to compute the weights Gradients are a proxy of how poorly a data point is classified Adaboost is a special case of gradient boosting 3.0.2 Gradient Boosting Boosting paradigm extended to general loss functions Beyond squared and exponential loss Any loss function that’s differentiable and convex Gradient Descent + Boosting Derivation \\(F(x_i) = \\sum_m \\alpha_m f_m(x_i)\\) \\(f_m(x_i) = \\arg \\min_{f \\in H} L(F(x_i) + \\alpha f_m(x_i))\\) This optimization is analogous to gradient descent in functional space Taylor Approximation \\(\\min L(F(x_i) + \\alpha f_m(x_i))\\) \\(\\min L(F(x_i)) + &lt;\\alpha f_m(x_i), \\frac{\\delta L}{\\delta F} &gt;\\) The first term is constant The second term is inner product over two functions \\(\\min &lt;\\alpha f_m(x_i), \\frac{\\delta L}{\\delta F} &gt;\\) Only interested in the behaviour of these function over training data Evaluate this functions at different points in training data Take the inner product \\(\\min \\sum_i \\frac{\\delta L}{\\delta F(x_i)} \\times \\alpha f(x_i)\\) Pseudo-Residual \\(-\\frac{\\delta L}{\\delta F(x_i)}\\) \\(\\min - \\sum_i r_i \\times \\alpha f(x_i)\\) The ensemble makes improvement as long as \\(\\sum_i r_i f(x_i) &lt; 0\\) Modifications for CART: Using CART as weak learners The minimization problem from Taylor approx can’t be directly optimized by CART Need to modify this to a functional form that can be easily handled (squared loss) \\(r_i\\) is independent of \\(f_m\\), hence \\(\\sum r_i ^2\\) is a constant \\(\\sum \\alpha f_m (x_i) ^2\\) can also be treated as a constant Scale factor to restrict the predictions to certain range \\(\\min \\sum r_i ^2 -2 \\sum_i r_i \\times \\alpha f(x_i) + \\sum \\alpha f_m (x_i) ^2\\) \\(\\min \\sum (r_i - \\alpha f(x_i))^2\\) This squared-loss can be minimized by CART easily Optimal value of \\(\\alpha\\) via Line Search \\(L = \\sum (r_i - \\alpha f(x_i))^2\\) \\(\\alpha^* = \\frac{\\sum r_i f(x_i)}{\\sum f(x_i)^2} \\approx 1\\) Algorithm Given Data \\(\\lbrace x_i, y_i \\rbrace\\) Loss Function \\(L(y_i, F(x_i))\\) Initialize the model with a constant value \\(\\min L(y_i, \\gamma)\\) Compute the pseudo residual \\(r_{im} = -\\frac{\\delta L(y_i, F(x_i))}{\\delta F(x_i)}\\) Build the new weak learner on pseudo residuals Say a decision tree \\(\\gamma_{jm} = \\arg\\min \\sum_{x_\\in R_{ij}} L(y_i, F_m(x_i) + \\gamma)\\) Optimal \\(\\gamma_{jm}\\) value is the average of residuals in the leaf node j Only in case of squared loss L in regression setting Update the ensemble \\(F_{m+1}(x_i) = F_m(x_i) + \\nu \\sum_j \\gamma_{jm} I(x_i \\in R_{jm})\\) \\(\\nu\\) is the step size or shrinkage It prevents overfitting 1st order Taylor approximation works only for small changes Extension to Classification Build a weak learner to predict log-odds Log Odds to Probability: \\(p = \\frac{e^{\\log(odds)}}{1+ e^{\\log(odds)}}\\) Objective is to minimize Negative Log-Likelihood \\(NLL = - \\sum y_i \\log(p_i) + (1 - y_i) \\log(1-p_i)\\) \\(NLL = - \\sum y_i \\log(\\frac{p_i}{1-p_i}) + log(1-p_i)\\) \\(NLL = - \\sum y_i \\log(odds) - \\log(1 + \\exp^{\\log(odds)})\\) Compute Psuedo Residuals \\(\\frac{\\delta NLL}{\\delta \\log(odds)}\\) \\(r_{im} = p_i - y_i\\) Algorithm Given Data \\(\\lbrace x_i, y_i \\rbrace\\) Loss Function \\(L(y_i, F(x_i))\\) Initialize the model with a constant value Log-Odds that minimizes NLL \\(\\min L(y_i, \\gamma)\\) Calculate Psuedo Residuals \\(r_{im} = p_i - y_i\\) Build the new weak learner on pseudo residuals \\(\\gamma_{jm} = \\arg \\min \\sum_{x_\\in R_{ij}} L(y_i, F_m(x_i) + \\gamma)\\) Minimizing this function not easy Use 2nd order Taylor Approximation - \\(\\min L(y_i, F(x_i) + \\gamma) = C + \\gamma \\frac{dL}{dF} + {1 \\over 2}\\gamma^2 \\frac{d^2L}{dF^2}\\) \\(\\gamma^* = - \\frac{dL}{dF} / \\frac{d^2L}{dF^2}\\) \\(\\frac{dL}{dF} = p_i - y_i\\) \\(\\frac{d^2L}{dF^2} = p_i (1 - p_i)\\) \\(\\gamma^* = \\frac{p_i - y_i}{p_i (1 - p_i)}\\) Update the ensemble \\(F_{m+1}(x_i) = F_m(x_i) + \\nu \\sum_j \\gamma_{jm} I(x_i \\in R_{jm})\\) 3.0.3 Adaboost for Classification Additively combines many weak learners to make classifications Adaptively re-weights incorrectly classified points Some weak learners get more weights in the final ensemble than others Each subsequent learner accounts for the mistakes made by the previous one Uses exponential loss \\(y \\in \\{-1,1\\}\\) \\(L(y_i, f(x_i)) = \\exp^{-y_i f(x_i)}\\) Upper bound on 0-1 loss, same as logistic loss Rises more sharply than logistic loss in case of wrong predictions LogitBoost minimizes logistic loss \\(\\log(1 + \\exp^{-y_i f(x_i)})\\) Objective Function Additive Ensemble: \\(F(x) = \\sum_m \\alpha_j f_j(x)\\) Loss: \\(L = \\sum_i \\exp^{-\\frac{1}{2} y_i \\times F(x)}\\) At mth round: \\(L = \\sum_i \\exp^{- \\frac{1}{2} y_i \\times \\sum_m \\alpha_m f_m(x)}\\) \\(L = \\sum_i \\exp^{-\\frac{1}{2} y_i \\times \\sum_{m-1} \\alpha_j f_j(x)} \\times \\exp^{- \\frac{1}{2} y_i \\alpha_m f_m(x_i)}\\) Assume all the values till m-1 as constant \\(L = \\sum_i w^m_i \\times \\exp^{- \\frac{1}{2} y_i \\alpha_m f_m(x_i)}\\) Minimizie E wrt to \\(\\alpha_m\\) to find the optimal value \\(L = \\sum_{corr} w^m_i \\exp^{- \\frac{1}{2} \\alpha_m} + \\sum_{incorr} w^m_i \\exp^{ \\frac{1}{2} \\alpha_m}\\) Assuming \\(\\epsilon_m\\) as the weighted misclassification error \\(L = \\epsilon_m \\exp^{\\frac{1}{2} \\alpha_m} + (1-\\epsilon_m) \\exp^{- \\frac{1}{2} \\alpha_m}\\) Optimal value of \\(\\alpha_m^* = \\frac{1}{2}\\log\\lbrack \\frac{1-\\epsilon_m}{\\epsilon_m} \\rbrack\\) Algorithm Initialization: Give equal weights to all observations For next m rounds: Fit a weak learner Calculate weighted error \\(\\epsilon_m\\) \\(\\epsilon_m = \\frac{\\sum_i w_i^m I(y_i \\ne f_m(x_i))}{\\sum_i w_i^m}\\) Calculate the weight of the new weak learner \\(\\alpha_m = \\frac{1}{2}\\log\\lbrack \\frac{1-\\epsilon_m}{\\epsilon_m} \\rbrack\\) Update the sample weights \\(w_i^{m+1} = w_i^{m} \\times \\exp^{\\alpha^m \\times I(y_i \\ne f_m(x_i))}\\) Normalize Scale factor \\(2 \\sqrt{\\epsilon(1-\\epsilon)}\\) Can be modified to work with regression problems 3.0.4 Notes Gradient boosting uses weak learners which have high bias and low variance and gradually reduces the bias over the ensemble by sequentially combining these weak learners Chronology: Adaboost Adaboost as gradient descent Generalize adaboost to any gradient descent Difference between Gradient Descent and Gradient Boosting In gradient descent, the gradients are used to update parameters of the model In gradient boosting, the gradients are used to build new models Gradient boosting is a meta model that combines weak learners "],["xgboost.html", "4 XGBoost", " 4 XGBoost Extreme Gradient Boosting Introduces regularization to reduce overfitting 4.0.1 Mathematical Details Loss Function \\(L(y_i, p_i)\\) MSE \\({1 \\over 2}\\sum{(y_i - p_i)^2}\\) NLL Loss \\(- \\sum {y_i \\log p_i + (1 - y_i) \\log (1 -p_i)}\\) In XGBoost, the objective has regularization terms \\(\\sum_i L(y_i, p_i) + \\gamma T + {1 \\over 2} \\lambda O_{value}^2\\) \\(O_{value}\\) is the prediction from tree (terminal value in leaf nodes) \\(p_i = p_i^0 + O_{value}\\) \\(p_i^0\\) is the initital prediction / prediction from previous round High values of \\(\\lambda\\) will push the optimal output values close to 0 Second-order Taylor approximation to simplify the objective \\(L(y_i, p_i^0 + O_{value})\\) \\(L(y_i, p_i^0) + \\frac{dL}{dO_{value}} O_{value} + {1 \\over 2} \\frac{d^2L}{dO_{value}^2} O_{value}^2\\) \\(L(y_i, p_i^0) + g O_{value} + {1 \\over 2} H O_{value}^2\\) \\(L(y_i, p_i^0)\\) is constant \\(\\sum_i L(y_i, p_i) = \\sum_i g_i O_{value} + {1 \\over 2} \\sum H_i O_{value}^2\\) Objective Function \\(\\sum_i L(y_i, p_i) + \\gamma T + {1 \\over 2} \\lambda O_{value}^2\\) \\(\\sum_i g_i O_{value} + \\gamma T + {1 \\over 2} (\\sum H_i + \\lambda) O_{value}^2\\) Optimal output value Differentiate objective function wrt \\(O_{value}\\) \\(O_{value}^* = - \\frac{\\sum g_i}{\\sum H_i + \\lambda}\\) For MSE: \\(g_i = - (y_i - p_i^0)\\) \\(H_i = 1\\) For NLL Output value is log(odds) \\(g_i = - (y_i - p_i)\\) \\(H_i = p_i (1 - p_i)\\) Splitting Criteria Objective value at optimal output \\(\\sum_i g_i O_{value} + \\gamma T + {1 \\over 2} (\\sum H_i + \\lambda) O_{value}^2\\) \\({1 \\over 2}{\\sum_i g_i^2 \\over \\sum H_i + \\lambda} + \\gamma T\\) 4.0.2 Regression Calculate similarity score \\(G^2 / (H + \\lambda)\\) \\(\\lambda\\) is the regularization parameter Reduces sensitivity to a particular observation Large values will result in more pruning (shrinks similarity scores) In case of MSE loss function \\(\\sum_i r_i^2 / (N + \\lambda)\\) \\(r\\) is the residual \\(N\\) is the number of observations in the node Calculate Gain for a split \\(\\mathrm{Gain} = \\mathrm{Similarity_{left}} + \\mathrm{Similarity_{right}} - \\mathrm{Similarity_{root}}\\) Split criterion \\(\\mathrm{Gain} - \\gamma &gt; 0\\) \\(\\gamma\\) controls tree complexity Helps prevent over fitting Setting \\(\\gamma = 0\\) doesn’t turn-off pruning Pruning Max-depth Cover / Minimum weight of leaf node N for regression Trees are grown fully before pruning If a child node satisfies minimum Gain but root doesn’t, the child will still exist Output Value of Tree \\(\\sum_i r_i / (N + \\lambda)\\) Output Value of Ensemble Initial Prediction + \\(\\eta\\) Output Value of 1st Tree …. Initial prediction is the simple average of target \\(\\eta\\) is the learning rate 4.0.3 Classification Calculate similarity score \\(G^2 / (H + \\lambda)\\) In case of Log loss function \\(\\sum r_i^2 / (\\sum{p_i (1-p_i)} + \\lambda)\\) \\(r\\) is the residual \\(p\\) is the previous probability estimate Calculate Gain for a split \\(\\mathrm{Gain} = \\mathrm{Similarity_{left}} + \\mathrm{Similarity_{right}} - \\mathrm{Similarity_{root}}\\) Split criterion \\(\\mathrm{Gain} - \\gamma &gt; 0\\) Pruning Max Depth Cover / Minimum weight of leaf node \\(\\sum{p_i (1-p_i)}\\) Output Value of Tree \\(\\sum r_i / (\\sum{p_i (1-p_i)} + \\lambda)\\) Output Value of Ensemble Intial prediction Simple average of target Convert the value to log(odds) Initial Prediction + \\(\\eta\\) Output Value of 1st Tree …. Output is log(odds) Transform the value to probability 4.0.4 Optimizations Approximate Greedy Algorithm Finding splits faster Histogram based splits by bucketing the variables Quantile Sketch Algorithm Approximately calculate the quantiles parallely Quantiles are weighted by cover / hessian Sparsity Aware Split Finding Calculate the split based on known data values of the variable For missing data: Send the observations to left node and calcluate the Gain Send the observations to right node and calcluate the Gain Evaluate which path gives maximum Gain Cache Aware Access Stores gradients and hessians in Cache Compress the data and store on hard-drive for faster access 4.0.5 Comparisons XGBoost Stochastic Gradient Boosting No Treatment for categorical variables Depth-wise tree growth LightGBM Gradient One-Side Sampling (GOSS) Maximum Gradient Observation are oversampled Encoding for categorical variables Exclusive Feature Bundling to reduce number of features Histrogram based splitting Leaf-wise tree growth CatBoost Minimum Variance Sampling Superior encoding technniques for categorical variables Target encoding Symmetric tree growth "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
