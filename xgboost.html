<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 XGBoost | Notes on ML</title>
  <meta name="description" content="4 XGBoost | Notes on ML" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4 XGBoost | Notes on ML" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 XGBoost | Notes on ML" />
  
  
  

<meta name="author" content="brightertiger" />


<meta name="date" content="2022-03-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="boosting.html"/>

<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ML Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a></li>
<li class="chapter" data-level="2" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html"><i class="fa fa-check"></i><b>2</b> Decision Trees &amp; Random Forests</a>
<ul>
<li class="chapter" data-level="2.0.1" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#decision-trees"><i class="fa fa-check"></i><b>2.0.1</b> Decision Trees</a></li>
<li class="chapter" data-level="2.0.2" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#splitting"><i class="fa fa-check"></i><b>2.0.2</b> Splitting</a></li>
<li class="chapter" data-level="2.0.3" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>2.0.3</b> Bias-Variance Trade-off</a></li>
<li class="chapter" data-level="2.0.4" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#nature-of-decision-trees"><i class="fa fa-check"></i><b>2.0.4</b> Nature of Decision Trees</a></li>
<li class="chapter" data-level="2.0.5" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#bagging"><i class="fa fa-check"></i><b>2.0.5</b> Bagging</a></li>
<li class="chapter" data-level="2.0.6" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#random-forest"><i class="fa fa-check"></i><b>2.0.6</b> Random Forest</a></li>
<li class="chapter" data-level="2.0.7" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#extratrees"><i class="fa fa-check"></i><b>2.0.7</b> ExtraTrees</a></li>
<li class="chapter" data-level="2.0.8" data-path="decision-trees-random-forests.html"><a href="decision-trees-random-forests.html#variable-importance"><i class="fa fa-check"></i><b>2.0.8</b> Variable Importance</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>3</b> Boosting</a>
<ul>
<li class="chapter" data-level="3.0.1" data-path="boosting.html"><a href="boosting.html#overview"><i class="fa fa-check"></i><b>3.0.1</b> Overview</a></li>
<li class="chapter" data-level="3.0.2" data-path="boosting.html"><a href="boosting.html#gradient-boosting"><i class="fa fa-check"></i><b>3.0.2</b> Gradient Boosting</a></li>
<li class="chapter" data-level="3.0.3" data-path="boosting.html"><a href="boosting.html#adaboost-for-classification"><i class="fa fa-check"></i><b>3.0.3</b> Adaboost for Classification</a></li>
<li class="chapter" data-level="3.0.4" data-path="boosting.html"><a href="boosting.html#notes"><i class="fa fa-check"></i><b>3.0.4</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="xgboost.html"><a href="xgboost.html"><i class="fa fa-check"></i><b>4</b> XGBoost</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="xgboost.html"><a href="xgboost.html#mathematical-details"><i class="fa fa-check"></i><b>4.0.1</b> Mathematical Details</a></li>
<li class="chapter" data-level="4.0.2" data-path="xgboost.html"><a href="xgboost.html#regression"><i class="fa fa-check"></i><b>4.0.2</b> Regression</a></li>
<li class="chapter" data-level="4.0.3" data-path="xgboost.html"><a href="xgboost.html#classification"><i class="fa fa-check"></i><b>4.0.3</b> Classification</a></li>
<li class="chapter" data-level="4.0.4" data-path="xgboost.html"><a href="xgboost.html#optimizations"><i class="fa fa-check"></i><b>4.0.4</b> Optimizations</a></li>
<li class="chapter" data-level="4.0.5" data-path="xgboost.html"><a href="xgboost.html#comparisons"><i class="fa fa-check"></i><b>4.0.5</b> Comparisons</a></li>
</ul></li>
<li class="divider"></li>
<li>Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes on ML</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="xgboost" class="section level1" number="4">
<h1><span class="header-section-number">4</span> XGBoost</h1>
<ul>
<li>Extreme Gradient Boosting</li>
<li>Introduces regularization to reduce overfitting</li>
</ul>
<div id="mathematical-details" class="section level3" number="4.0.1">
<h3><span class="header-section-number">4.0.1</span> Mathematical Details</h3>
<ul>
<li>Loss Function
<ul>
<li><span class="math inline">\(L(y_i, p_i)\)</span></li>
<li>MSE
<ul>
<li><span class="math inline">\({1 \over 2}\sum{(y_i - p_i)^2}\)</span></li>
</ul></li>
<li>NLL Loss
<ul>
<li><span class="math inline">\(- \sum {y_i \log p_i + (1 - y_i) \log (1 -p_i)}\)</span><br />
</li>
</ul></li>
</ul></li>
<li>In XGBoost, the objective has regularization terms
<ul>
<li><span class="math inline">\(\sum_i L(y_i, p_i) + \gamma T + {1 \over 2} \lambda O_{value}^2\)</span></li>
<li><span class="math inline">\(O_{value}\)</span> is the prediction from tree (terminal value in leaf nodes)</li>
<li><span class="math inline">\(p_i = p_i^0 + O_{value}\)</span></li>
<li><span class="math inline">\(p_i^0\)</span> is the initital prediction / prediction from previous round</li>
</ul></li>
<li>High values of <span class="math inline">\(\lambda\)</span> will push the optimal output values close to 0</li>
<li>Second-order Taylor approximation to simplify the objective
<ul>
<li><span class="math inline">\(L(y_i, p_i^0 + O_{value})\)</span></li>
<li><span class="math inline">\(L(y_i, p_i^0) + \frac{dL}{dO_{value}} O_{value} + {1 \over 2} \frac{d^2L}{dO_{value}^2} O_{value}^2\)</span></li>
<li><span class="math inline">\(L(y_i, p_i^0) + g O_{value} + {1 \over 2} H O_{value}^2\)</span></li>
<li><span class="math inline">\(L(y_i, p_i^0)\)</span> is constant</li>
<li><span class="math inline">\(\sum_i L(y_i, p_i) = \sum_i g_i O_{value} + {1 \over 2} \sum H_i O_{value}^2\)</span></li>
</ul></li>
<li>Objective Function
<ul>
<li><span class="math inline">\(\sum_i L(y_i, p_i) + \gamma T + {1 \over 2} \lambda O_{value}^2\)</span></li>
<li><span class="math inline">\(\sum_i g_i O_{value} + \gamma T + {1 \over 2} (\sum H_i + \lambda) O_{value}^2\)</span></li>
</ul></li>
<li>Optimal output value
<ul>
<li>Differentiate objective function wrt <span class="math inline">\(O_{value}\)</span></li>
<li><span class="math inline">\(O_{value}^* = - \frac{\sum g_i}{\sum H_i + \lambda}\)</span></li>
<li>For MSE:
<ul>
<li><span class="math inline">\(g_i = - (y_i - p_i^0)\)</span></li>
<li><span class="math inline">\(H_i = 1\)</span></li>
</ul></li>
<li>For NLL
<ul>
<li>Output value is log(odds)</li>
<li><span class="math inline">\(g_i = - (y_i - p_i)\)</span></li>
<li><span class="math inline">\(H_i = p_i (1 - p_i)\)</span></li>
</ul></li>
</ul></li>
<li>Splitting Criteria
<ul>
<li>Objective value at optimal output</li>
<li><span class="math inline">\(\sum_i g_i O_{value} + \gamma T + {1 \over 2} (\sum H_i + \lambda) O_{value}^2\)</span></li>
<li><span class="math inline">\({1 \over 2}{\sum_i g_i^2 \over \sum H_i + \lambda} + \gamma T\)</span></li>
</ul></li>
</ul>
</div>
<div id="regression" class="section level3" number="4.0.2">
<h3><span class="header-section-number">4.0.2</span> Regression</h3>
<ul>
<li>Calculate similarity score
<ul>
<li><span class="math inline">\(G^2 / (H + \lambda)\)</span></li>
<li><span class="math inline">\(\lambda\)</span> is the regularization parameter</li>
<li>Reduces sensitivity to a particular observation</li>
<li>Large values will result in more pruning (shrinks similarity scores)</li>
<li>In case of MSE loss function
<ul>
<li><span class="math inline">\(\sum_i r_i^2 / (N + \lambda)\)</span></li>
<li><span class="math inline">\(r\)</span> is the residual</li>
<li><span class="math inline">\(N\)</span> is the number of observations in the node</li>
</ul></li>
</ul></li>
<li>Calculate Gain for a split
<ul>
<li><span class="math inline">\(\mathrm{Gain} = \mathrm{Similarity_{left}} + \mathrm{Similarity_{right}} - \mathrm{Similarity_{root}}\)</span><br />
</li>
</ul></li>
<li>Split criterion
<ul>
<li><span class="math inline">\(\mathrm{Gain} - \gamma &gt; 0\)</span></li>
<li><span class="math inline">\(\gamma\)</span> controls tree complexity</li>
<li>Helps prevent over fitting</li>
<li>Setting <span class="math inline">\(\gamma = 0\)</span> doesn’t turn-off pruning</li>
</ul></li>
<li>Pruning
<ul>
<li>Max-depth</li>
<li>Cover / Minimum weight of leaf node
<ul>
<li>N for regression</li>
</ul></li>
<li>Trees are grown fully before pruning
<ul>
<li>If a child node satisfies minimum Gain but root doesn’t, the child will still exist</li>
</ul></li>
</ul></li>
<li>Output Value of Tree
<ul>
<li><span class="math inline">\(\sum_i r_i / (N + \lambda)\)</span><br />
</li>
</ul></li>
<li>Output Value of Ensemble
<ul>
<li>Initial Prediction + <span class="math inline">\(\eta\)</span> Output Value of 1st Tree ….</li>
<li>Initial prediction is the simple average of target</li>
<li><span class="math inline">\(\eta\)</span> is the learning rate</li>
</ul></li>
</ul>
</div>
<div id="classification" class="section level3" number="4.0.3">
<h3><span class="header-section-number">4.0.3</span> Classification</h3>
<ul>
<li>Calculate similarity score
<ul>
<li><span class="math inline">\(G^2 / (H + \lambda)\)</span></li>
<li>In case of Log loss function
<ul>
<li><span class="math inline">\(\sum r_i^2 / (\sum{p_i (1-p_i)} + \lambda)\)</span></li>
<li><span class="math inline">\(r\)</span> is the residual</li>
<li><span class="math inline">\(p\)</span> is the previous probability estimate</li>
</ul></li>
</ul></li>
<li>Calculate Gain for a split
<ul>
<li><span class="math inline">\(\mathrm{Gain} = \mathrm{Similarity_{left}} + \mathrm{Similarity_{right}} - \mathrm{Similarity_{root}}\)</span><br />
</li>
</ul></li>
<li>Split criterion
<ul>
<li><span class="math inline">\(\mathrm{Gain} - \gamma &gt; 0\)</span></li>
</ul></li>
<li>Pruning
<ul>
<li>Max Depth</li>
<li>Cover / Minimum weight of leaf node
<ul>
<li><span class="math inline">\(\sum{p_i (1-p_i)}\)</span></li>
</ul></li>
</ul></li>
<li>Output Value of Tree
<ul>
<li><span class="math inline">\(\sum r_i / (\sum{p_i (1-p_i)} + \lambda)\)</span></li>
</ul></li>
<li>Output Value of Ensemble
<ul>
<li>Intial prediction
<ul>
<li>Simple average of target<br />
</li>
<li>Convert the value to log(odds)</li>
</ul></li>
<li>Initial Prediction + <span class="math inline">\(\eta\)</span> Output Value of 1st Tree ….</li>
<li>Output is log(odds)</li>
<li>Transform the value to probability</li>
</ul></li>
</ul>
</div>
<div id="optimizations" class="section level3" number="4.0.4">
<h3><span class="header-section-number">4.0.4</span> Optimizations</h3>
<ul>
<li>Approximate Greedy Algorithm
<ul>
<li>Finding splits faster</li>
<li>Histogram based splits by bucketing the variables</li>
</ul></li>
<li>Quantile Sketch Algorithm
<ul>
<li>Approximately calculate the quantiles parallely</li>
<li>Quantiles are weighted by cover / hessian<br />
</li>
</ul></li>
<li>Sparsity Aware Split Finding
<ul>
<li>Calculate the split based on known data values of the variable</li>
<li>For missing data:
<ul>
<li>Send the observations to left node and calcluate the Gain</li>
<li>Send the observations to right node and calcluate the Gain</li>
</ul></li>
<li>Evaluate which path gives maximum Gain</li>
</ul></li>
<li>Cache Aware Access
<ul>
<li>Stores gradients and hessians in Cache</li>
<li>Compress the data and store on hard-drive for faster access</li>
</ul></li>
</ul>
</div>
<div id="comparisons" class="section level3" number="4.0.5">
<h3><span class="header-section-number">4.0.5</span> Comparisons</h3>
<ul>
<li>XGBoost
<ul>
<li>Stochastic Gradient Boosting</li>
<li>No Treatment for categorical variables</li>
<li>Depth-wise tree growth</li>
</ul></li>
<li>LightGBM
<ul>
<li>Gradient One-Side Sampling (GOSS)
<ul>
<li>Maximum Gradient Observation are oversampled</li>
</ul></li>
<li>Encoding for categorical variables</li>
<li>Exclusive Feature Bundling to reduce number of features</li>
<li>Histrogram based splitting</li>
<li>Leaf-wise tree growth</li>
</ul></li>
<li>CatBoost
<ul>
<li>Minimum Variance Sampling</li>
<li>Superior encoding technniques for categorical variables
<ul>
<li>Target encoding</li>
</ul></li>
<li>Symmetric tree growth</li>
</ul></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="boosting.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
